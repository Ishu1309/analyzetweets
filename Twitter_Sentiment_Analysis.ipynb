{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all the outputs in a cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "%autosave 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Trump File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('Trump.txt','r') \n",
    "#open the file in read mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump = f.read()  \n",
    "#read the trump file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'RT @Nettaaaaaaaa: Really wild how the insane things he said about Ferguson &amp; the death of Mike Brown Jr. were overlooked. https://t.co/R9Nd\\xe2\\x80\\xa6\\n'b'RT @Maria_squirt: @usaguy @JMoore821 @Havok_2018 @DanielBeerthuis @realDonaldTrump @LunaLuvgood2017 @StormResist @NatCookResists @DanaScott\\xe2\\x80\\xa6\\n'b'RT @NBCNews: Deputy AG Rosenstein directly approved application for search warrant on Trump personal attorney Michael Cohen, person with kn\\xe2\\x80\\xa6\\n'b'RT @HoarseWisperer: BWAHAHAHAHHAHAHAA.\\n\\nTrump fired Preet Bharara and personally interviewed and appointed his replacement...\\n\\n...and then\\xe2\\x80\\xa6\\n'b'RT @GreggJarrett: I\\xe2\\x80\\x99ve written a book, soon to be published:  \\xe2\\x80\\x9cThe Russia Hoax: The Illicit Scheme to Clear Hillary Clinton and Frame Donal\\xe2\\x80\\xa6\\n'b\"@hughhewitt @realDonaldTrump Oh, puh-leeze, Hugh.\\nTrump's personally interviewed and appointed AG signed off on thi\\xe2\\x80\\xa6 https://t.co/vWBOXdNXP9\\n\"b'RT @eugenegu: What a powerful th\n"
     ]
    }
   ],
   "source": [
    "print(trump[:1000])  \n",
    "#printing a sample data just to get a basic idea about cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trump)\n",
    "#to check the type "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw tweets for word 'trump'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243459"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trump)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning HTTP Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "result = re.sub(r\"http\\S+\", \"\", trump)    \n",
    "#Cleaning the http tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'RT @Nettaaaaaaaa: Really wild how the insane things he said about Ferguson &amp; the death of Mike Brown Jr. were overlooked.  @Maria_squirt: @usaguy @JMoore821 @Havok_2018 @DanielBeerthuis @realDonaldTrump @LunaLuvgood2017 @StormResist @NatCookResists @DanaScott\\xe2\\x80\\xa6\\n'b'RT @NBCNews: Deputy AG Rosenstein directly approved application for search warrant on Trump personal attorney Michael Cohen, person with kn\\xe2\\x80\\xa6\\n'b'RT @HoarseWisperer: BWAHAHAHAHHAHAHAA.\\n\\nTrump fired Preet Bharara and personally interviewed and appointed his replacement...\\n\\n...and then\\xe2\\x80\\xa6\\n'b'RT @GreggJarrett: I\\xe2\\x80\\x99ve written a book, soon to be published:  \\xe2\\x80\\x9cThe Russia Hoax: The Illicit Scheme to Clear Hillary Clinton and Frame Donal\\xe2\\x80\\xa6\\n'b\"@hughhewitt @realDonaldTrump Oh, puh-leeze, Hugh.\\nTrump's personally interviewed and appointed AG signed off on thi\\xe2\\x80\\xa6  @eugenegu: What a powerful thread on the true nature of American politics, the rise of Trump, t\n"
     ]
    }
   ],
   "source": [
    "print(result[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning embedded computer code with pattern of \\xe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1= re.sub(r'(\\\\x(.){2})', '',result) \n",
    "#Cleaning the embedded code by computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'RT @Nettaaaaaaaa: Really wild how the insane things he said about Ferguson &amp; the death of Mike Brown Jr. were overlooked.  @Maria_squirt: @usaguy @JMoore821 @Havok_2018 @DanielBeerthuis @realDonaldTrump @LunaLuvgood2017 @StormResist @NatCookResists @DanaScott\\n'b'RT @NBCNews: Deputy AG Rosenstein directly approved application for search warrant on Trump personal attorney Michael Cohen, person with kn\\n'b'RT @HoarseWisperer: BWAHAHAHAHHAHAHAA.\\n\\nTrump fired Preet Bharara and personally interviewed and appointed his replacement...\\n\\n...and then\\n'b'RT @GreggJarrett: Ive written a book, soon to be published:  The Russia Hoax: The Illicit Scheme to Clear Hillary Clinton and Frame Donal\\n'b\"@hughhewitt @realDonaldTrump Oh, puh-leeze, Hugh.\\nTrump's personally interviewed and appointed AG signed off on thi  @eugenegu: What a powerful thread on the true nature of American politics, the rise of Trump, the root of white supremacy, and the solut\\n'b'Queen Elizabeth likens Trump to noisy helicopter  @krassenstein: The chairman of Sinclair TV, David Smith, met with Trump.\\n\\n\"We are here to deliver your message,\" Smith told the Presiden\\n'b'RT @WSJ: Lawyers for Trump company in Panama sought help from its president in a dispute over control of a luxury hotel \\n @kevinjohnson510: Clint Eastwood defending Donald Trump claimed that we live in a generation of pussies  @michelle_bocik: From Cohen raid US Attorney of the Southern District of New York, Geoffrey Berman, a Trump appoint, gets the Stormy Dan\\n'b\"Fox legal analyst defends Cohen raid -- and seconds later Trump explodes in hysteria over Mueller's 'witch hunt'  @krassenstein: Trump canceled his trip to South America for one reason only.\\n\\nHe can't watch Fox News in South America to hear how Muell\\n\"b'@jonkarl your Tweet was quoted in an article by @CNBC   @sarahkendzior: Rosenstein's new deputy, Edward O'Callaghan, assisted the Trump transition team.\\n\\nRick Gates, a key figure in the Russia\\n\"b'TWO WOMEN ARE SAID T\n"
     ]
    }
   ],
   "source": [
    "print(result1[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing the retweets and &amp and \\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b' @Nettaaaaaaaa: Really wild how the insane things he said about Ferguson ; the death of Mike Brown Jr. were overlooked.  @Maria_squirt: @usaguy @JMoore821 @Havok_2018 @DanielBeerthuis @realDonaldTrump @LunaLuvgood2017 @StormResist @NatCookResists @DanaScott'b' @NBCNews: Deputy AG Rosenstein directly approved application for search warrant on Trump personal attorney Michael Cohen, person with kn'b' @HoarseWisperer: BWAHAHAHAHHAHAHAA.Trump fired Preet Bharara and personally interviewed and appointed his replacement......and then'b' @GreggJarrett: Ive written a book, soon to be published:  The Russia Hoax: The Illicit Scheme to Clear Hillary Clinton and Frame Donal'b\"@hughhewitt @realDonaldTrump Oh, puh-leeze, Hugh.Trump's personally interviewed and appointed AG signed off on thi  @eugenegu: What a powerful thread on the true nature of American politics, the rise of Trump, the root of white supremacy, and the solut'b'Queen Elizabeth likens Trump to noisy helicopter  @krassenstein: The chairman of Sinclair TV, David Smith, met with Trump.\"We are here to deliver your message,\" Smith told the Presiden'b' @WSJ: Lawyers for Trump company in Panama sought help from its president in a dispute over control of a luxury hotel  @kevinjohnson510: Clint Eastwood defending Donald Trump claimed that we live in a generation of pussies  @michelle_bocik: From Cohen raid US Attorney of the Southern District of New York, Geoffrey Berman, a Trump appoint, gets the Stormy Dan'b\"Fox legal analyst defends Cohen raid -- and seconds later Trump explodes in hysteria over Mueller's 'witch hunt'  @krassenstein: Trump canceled his trip to South America for one reason only.He can't watch Fox News in South America to hear how Muell\"b'@jonkarl your Tweet was quoted in an article by @CNBC   @sarahkendzior: Rosenstein's new deputy, Edward O'Callaghan, assisted the Trump transition team.Rick Gates, a key figure in the Russia\"b'TWO WOMEN ARE SAID TO HAVE CLAIMED RELATIONS WITH TRUMP: NYT who gives 2shit\n"
     ]
    }
   ],
   "source": [
    "pun = ['RT','&amp','\\\\n']\n",
    "for i in pun:\n",
    "     if i in result1:\n",
    "            result1 = result1.replace(i,'')\n",
    "#removing the Retweets and &amp tags\n",
    "\n",
    "print(result1[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing all the punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "x = str.maketrans(\"\",\"\",string.punctuation)\n",
    "#Removing all the punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = result1.translate(x)    \n",
    "#Result after cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing sample data after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b Nettaaaaaaaa Really wild how the insane things he said about Ferguson  the death of Mike Brown Jr were overlooked  Mariasquirt usaguy JMoore821 Havok2018 DanielBeerthuis realDonaldTrump LunaLuvgood2017 StormResist NatCookResists DanaScottb NBCNews Deputy AG Rosenstein directly approved application for search warrant on Trump personal attorney Michael Cohen person with knb HoarseWisperer BWAHAHAHAHHAHAHAATrump fired Preet Bharara and personally interviewed and appointed his replacementand thenb GreggJarrett Ive written a book soon to be published  The Russia Hoax The Illicit Scheme to Clear Hillary Clinton and Frame Donalbhughhewitt realDonaldTrump Oh puhleeze HughTrumps personally interviewed and appointed AG signed off on thi  eugenegu What a powerful thread on the true nature of American politics the rise of Trump the root of white supremacy and the solutbQueen Elizabeth likens Trump to noisy helicopter  krassenstein The chairman of Sinclair TV David Smith met with TrumpWe are here\n"
     ]
    }
   ],
   "source": [
    "print(result3[:1000]) \n",
    "#checking the cleaned data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of data after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184874"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result3) #length of data after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result3) #type of sample after data cleaning is still the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To convert every character to lower case and then split it into list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = result3.lower().split()\n",
    "#to convert every character to lower case and then split it into list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(new) #checking the type of new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b', 'nettaaaaaaaa', 'really', 'wild', 'how', 'the', 'insane', 'things', 'he', 'said', 'about', 'ferguson', 'the', 'death', 'of', 'mike', 'brown', 'jr', 'were', 'overlooked', 'mariasquirt', 'usaguy', 'jmoore821', 'havok2018', 'danielbeerthuis', 'realdonaldtrump', 'lunaluvgood2017', 'stormresist', 'natcookresists', 'danascottb', 'nbcnews', 'deputy', 'ag', 'rosenstein', 'directly', 'approved', 'application', 'for', 'search', 'warrant', 'on', 'trump', 'personal', 'attorney', 'michael', 'cohen', 'person', 'with', 'knb', 'hoarsewisperer', 'bwahahahahhahahaatrump', 'fired', 'preet', 'bharara', 'and', 'personally', 'interviewed', 'and', 'appointed', 'his', 'replacementand', 'thenb', 'greggjarrett', 'ive', 'written', 'a', 'book', 'soon', 'to', 'be', 'published', 'the', 'russia', 'hoax', 'the', 'illicit', 'scheme', 'to', 'clear', 'hillary', 'clinton', 'and', 'frame', 'donalbhughhewitt', 'realdonaldtrump', 'oh', 'puhleeze', 'hughtrumps', 'personally', 'interviewed', 'and', 'appointed', 'ag', 'signed', 'off', 'on', 'thi', 'eugenegu', 'what', 'a']\n"
     ]
    }
   ],
   "source": [
    "print(new[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of new list created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29064"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new) #length of new after list creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b', 'nettaaaaaaaa', 'really', 'wild', 'how', 'the', 'insane', 'things', 'he', 'said', 'about', 'ferguson', 'the', 'death', 'of', 'mike', 'brown', 'jr', 'were', 'overlooked', 'mariasquirt', 'usaguy', 'jmoore821', 'havok2018', 'danielbeerthuis', 'realdonaldtrump', 'lunaluvgood2017', 'stormresist', 'natcookresists', 'danascottb', 'nbcnews', 'deputy', 'ag', 'rosenstein', 'directly', 'approved', 'application', 'for', 'search', 'warrant', 'on', 'trump', 'personal', 'attorney', 'michael', 'cohen', 'person', 'with', 'knb', 'hoarsewisperer', 'bwahahahahhahahaatrump', 'fired', 'preet', 'bharara', 'and', 'personally', 'interviewed', 'and', 'appointed', 'his', 'replacementand', 'thenb', 'greggjarrett', 'ive', 'written', 'a', 'book', 'soon', 'to', 'be', 'published', 'the', 'russia', 'hoax', 'the', 'illicit', 'scheme', 'to', 'clear', 'hillary', 'clinton', 'and', 'frame', 'donalbhughhewitt', 'realdonaldtrump', 'oh', 'puhleeze', 'hughtrumps', 'personally', 'interviewed', 'and', 'appointed', 'ag', 'signed', 'off', 'on', 'thi', 'eugenegu', 'what', 'a']\n"
     ]
    }
   ],
   "source": [
    "print(new[:100]) #printing the sample of this list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Positive words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = open('positive.txt','r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To read positive word list, change every character to lower case and split it into list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "pw = f2.read().lower().split()\n",
    "#to read positive word list, change every character to lower case and split it into list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pw) \n",
    "#type of pw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of positive words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2006"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pw)\n",
    "#number of positive words in list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample of positive words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a+', 'abound', 'abounds', 'abundance', 'abundant', 'accessable', 'accessible', 'acclaim', 'acclaimed', 'acclamation', 'accolade', 'accolades', 'accommodative', 'accomodative', 'accomplish', 'accomplished', 'accomplishment', 'accomplishments', 'accurate', 'accurately', 'achievable', 'achievement', 'achievements', 'achievible', 'acumen', 'adaptable', 'adaptive', 'adequate', 'adjustable', 'admirable', 'admirably', 'admiration', 'admire', 'admirer', 'admiring', 'admiringly', 'adorable', 'adore', 'adored', 'adorer', 'adoring', 'adoringly', 'adroit', 'adroitly', 'adulate', 'adulation', 'adulatory', 'advanced', 'advantage', 'advantageous', 'advantageously', 'advantages', 'adventuresome', 'adventurous', 'advocate', 'advocated', 'advocates', 'affability', 'affable', 'affably', 'affectation', 'affection', 'affectionate', 'affinity', 'affirm', 'affirmation', 'affirmative', 'affluence', 'affluent', 'afford', 'affordable', 'affordably', 'afordable', 'agile', 'agilely', 'agility', 'agreeable', 'agreeableness', 'agreeably', 'all-around', 'alluring', 'alluringly', 'altruistic', 'altruistically', 'amaze', 'amazed', 'amazement', 'amazes', 'amazing', 'amazingly', 'ambitious', 'ambitiously', 'ameliorate', 'amenable', 'amenity', 'amiability', 'amiabily', 'amiable', 'amicability', 'amicable']\n"
     ]
    }
   ],
   "source": [
    "print(pw[:100])\n",
    "#printing the sampled list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "f3 = open('neg.txt','r',encoding = \"ISO-8859-1\")\n",
    "#opening the file with negative word, since was in another format so converted to ISO format for compatibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the negative word list, changed it to lower case and then split them to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "nw = f3.read().lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nw) \n",
    "#to check the type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4783"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nw)\n",
    "#to check the length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample of negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2-faced', '2-faces', 'abnormal', 'abolish', 'abominable', 'abominably', 'abominate', 'abomination', 'abort', 'aborted', 'aborts', 'abrade', 'abrasive', 'abrupt', 'abruptly', 'abscond', 'absence', 'absent-minded', 'absentee', 'absurd', 'absurdity', 'absurdly', 'absurdness', 'abuse', 'abused', 'abuses', 'abusive', 'abysmal', 'abysmally', 'abyss', 'accidental', 'accost', 'accursed', 'accusation', 'accusations', 'accuse', 'accuses', 'accusing', 'accusingly', 'acerbate', 'acerbic', 'acerbically', 'ache', 'ached', 'aches', 'achey', 'aching', 'acrid', 'acridly', 'acridness', 'acrimonious', 'acrimoniously', 'acrimony', 'adamant', 'adamantly', 'addict', 'addicted', 'addicting', 'addicts', 'admonish', 'admonisher', 'admonishingly', 'admonishment', 'admonition', 'adulterate', 'adulterated', 'adulteration', 'adulterier', 'adversarial', 'adversary', 'adverse', 'adversity', 'afflict', 'affliction', 'afflictive', 'affront', 'afraid', 'aggravate', 'aggravating', 'aggravation', 'aggression', 'aggressive', 'aggressiveness', 'aggressor', 'aggrieve', 'aggrieved', 'aggrivation', 'aghast', 'agonies', 'agonize', 'agonizing', 'agonizingly', 'agony', 'aground', 'ail', 'ailing', 'ailment', 'aimless', 'alarm', 'alarmed']\n"
     ]
    }
   ],
   "source": [
    "print(nw[:100])\n",
    "#to print the sample of negative words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "f4 = open('stopwords.txt','r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the stop word list, changed it to lower case and then split them to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = f4.read().lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "423"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sw)\n",
    "#length of stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample of Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'across', 'after', 'again', 'against', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'among', 'an', 'and', 'another', 'any', 'anybody', 'anyone', 'anything', 'anywhere', 'are', 'area', 'areas', 'around', 'as', 'ask', 'asked', 'asking', 'asks', 'at', 'away', 'b', 'back', 'backed', 'backing', 'backs', 'be', 'became', 'because', 'become', 'becomes', 'been', 'before', 'began', 'behind', 'being', 'beings', 'best', 'better', 'between', 'big', 'both', 'but', 'by', 'c', 'came', 'can', 'cannot', 'case', 'cases', 'certain', 'certainly', 'clear', 'clearly', 'come', 'could', 'd', 'did', 'differ', 'different', 'differently', 'do', 'does', 'done', 'down', 'downed', 'downing', 'downs', 'during', 'e', 'each', 'early', 'either', 'end', 'ended', 'ending', 'ends', 'enough', 'even', 'evenly', 'ever', 'every', 'everybody', 'everyone', 'everything', 'everywhere']\n"
     ]
    }
   ],
   "source": [
    "print(sw[:100])\n",
    "#printing the stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the positive, negative, stop and other words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "pscore = 0 #to initialize the positive score variable\n",
    "p1 = []    #to create a list\n",
    "nscore = 0\n",
    "n1 = []\n",
    "sscore = 0\n",
    "s1 = []\n",
    "oscore = 0\n",
    "o1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in new:\n",
    "    if i !='trump':   #since trump can be a name so removing all the occurences of it as it might get counted in positive words\n",
    "        if i in pw: \n",
    "            pscore += 1\n",
    "            p1.append(i)\n",
    "        elif i in nw:\n",
    "            nscore -=1\n",
    "            n1.append(i)\n",
    "        elif i in sw:\n",
    "            sscore +=1\n",
    "            s1.append(i)\n",
    "        else:\n",
    "            oscore +=1\n",
    "            o1.append(i)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total positive word count in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623\n"
     ]
    }
   ],
   "source": [
    "print(pscore) #total positive score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Negative word count in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-886\n"
     ]
    }
   ],
   "source": [
    "print(nscore) #total negative score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: \n",
    "<b>The sum of positive words: 623 and the sum of negative words is: -886. The general sentiment is negative. For determining weakly or strongly negative, I have used ratio as below: </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = abs(pscore/nscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7031602708803611"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> I have defined the ratio here as: \n",
    "    <li>if abs(ratio)  >=0 and < 0.5 -> strongly negative </li>\n",
    "    <li>abs(ratio) >= 0.5 and  < 1 -> weakly negative</li>\n",
    "    <li>abs(ratio) >=1 and < 1.5 -> weakly positive</li>\n",
    "    <li>abs(ratio) >=1.5  -> strongly positive</li>\n",
    "      Since ratio is 0.7029478458049887.Based on the analysis here I think that the sentiment is weakly negative.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14725\n"
     ]
    }
   ],
   "source": [
    "print(oscore) #score of words which are neither positive nor negative or stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11953\n"
     ]
    }
   ],
   "source": [
    "print(sscore) #total stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clear', 'powerful', 'supremacy', 'luxury', 'supporter', 'winning', 'grand', 'master', 'grand', 'supporting', 'admire', 'top', 'protect', 'right', 'support', 'support', 'like', 'like', 'supports', 'great', 'great', 'well', 'obsession', 'leading', 'protection', 'right', 'privilege', 'loves', 'winning', 'like', 'well', 'like', 'like', 'whoa', 'poised', 'credible', 'strong', 'joy', 'worth', 'grand', 'worth', 'trust', 'faith', 'win', 'favor', 'like', 'right', 'privilege', 'wins', 'supreme', 'stunning', 'win', 'love', 'privilege', 'fun', 'helped', 'winning', 'well', 'like', 'happy', 'led', 'thank', 'winning', 'useful', 'privilege', 'stunning', 'victory', 'hero', 'perfectly', 'perfect', 'right', 'fair', 'supporting', 'top', 'loves', 'winning', 'work', 'privilege', 'enough', 'enough', 'success', 'great', 'thank', 'love', 'supporting', 'amazed', 'advantage', 'wonder', 'supreme', 'like', 'confidence', 'winning', 'important', 'love', 'like', 'liked', 'fine', 'protect', 'perfect', 'worth']\n"
     ]
    }
   ],
   "source": [
    "print(p1[:100]) #displaying the positive words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wild', 'insane', 'death', 'hoax', 'illicit', 'noisy', 'dispute', 'stormy', 'hysteria', 'unbelievable', 'disgraceful', 'attack', 'rumor', 'fraudulent', 'hell', 'wild', 'terror', 'lost', 'attacks', 'lying', 'fraud', 'corruption', 'noisy', 'guilty', 'complacent', 'inevitably', 'terrorism', 'spew', 'denying', 'stormy', 'wild', 'insane', 'death', 'threatening', 'bugging', 'biased', 'furious', 'crap', 'damn', 'break', 'disgraceful', 'attack', 'killed', 'disagree', 'overwhelming', 'dense', 'condemns', 'heinous', 'attack', 'involuntary', 'criminal', 'thug', 'hell', 'obsess', 'lies', 'breaking', 'resignation', 'embattled', 'unsafe', 'destroy', 'fake', 'criminal', 'hard', 'dispute', 'problem', 'subpoena', 'dump', 'dirty', 'dangerous', 'hard', 'outrageous', 'attacks', 'bigotry', 'condemns', 'heinous', 'attack', 'stormy', 'deny', 'worry', 'loses', 'stuck', 'criminal', 'corruption', 'refusing', 'lied', 'hell', 'crime', 'meltdown', 'doubt', 'crazy', 'explode', 'idiot', 'disgrace', 'issues', 'breaking', 'rogue', 'dirty', 'dead', 'attack', 'breaking']\n"
     ]
    }
   ],
   "source": [
    "print(n1[:100]) #displaying the negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b', 'really', 'how', 'the', 'things', 'he', 'said', 'about', 'the', 'of', 'were', 'for', 'on', 'with', 'and', 'and', 'his', 'a', 'to', 'be', 'the', 'the', 'to', 'and', 'and', 'off', 'on', 'what', 'a', 'on', 'the', 'of', 'the', 'of', 'the', 'of', 'and', 'the', 'to', 'the', 'of', 'with', 'are', 'here', 'to', 'your', 'the', 'for', 'in', 'from', 'its', 'in', 'a', 'over', 'of', 'a', 'that', 'we', 'in', 'a', 'of', 'from', 'us', 'of', 'the', 'of', 'new', 'a', 'gets', 'the', 'and', 'seconds', 'later', 'in', 'over', 'his', 'to', 'for', 'one', 'in', 'to', 'how', 'your', 'was', 'in', 'an', 'by', 'new', 'the', 'a', 'in', 'the', 'are', 'said', 'to', 'have', 'with', 'who', 'gives', 'a']\n"
     ]
    }
   ],
   "source": [
    "print(s1[:100]) #displaying the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nettaaaaaaaa', 'ferguson', 'mike', 'brown', 'jr', 'overlooked', 'mariasquirt', 'usaguy', 'jmoore821', 'havok2018', 'danielbeerthuis', 'realdonaldtrump', 'lunaluvgood2017', 'stormresist', 'natcookresists', 'danascottb', 'nbcnews', 'deputy', 'ag', 'rosenstein', 'directly', 'approved', 'application', 'search', 'warrant', 'personal', 'attorney', 'michael', 'cohen', 'person', 'knb', 'hoarsewisperer', 'bwahahahahhahahaatrump', 'fired', 'preet', 'bharara', 'personally', 'interviewed', 'appointed', 'replacementand', 'thenb', 'greggjarrett', 'ive', 'written', 'book', 'soon', 'published', 'russia', 'scheme', 'hillary', 'clinton', 'frame', 'donalbhughhewitt', 'realdonaldtrump', 'oh', 'puhleeze', 'hughtrumps', 'personally', 'interviewed', 'appointed', 'ag', 'signed', 'thi', 'eugenegu', 'thread', 'true', 'nature', 'american', 'politics', 'rise', 'root', 'white', 'solutbqueen', 'elizabeth', 'likens', 'helicopter', 'krassenstein', 'chairman', 'sinclair', 'tv', 'david', 'smith', 'met', 'trumpwe', 'deliver', 'message', 'smith', 'told', 'presidenb', 'wsj', 'lawyers', 'company', 'panama', 'sought', 'help', 'president', 'control', 'hotel', 'kevinjohnson510', 'clint']\n"
     ]
    }
   ],
   "source": [
    "print(o1[:100]) #displaying the other words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total count of all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28187"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = pscore + abs(nscore) + sscore + oscore #total count of all words\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ratio of positive word to the whole word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratiop = pscore/total #ratio of positive word to the whole word count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ratio of negative word to the whole word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "ration = abs(nscore)/total #ratio of negative word to the whole word count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ratio of Stop word to the whole word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = sscore/total #ratio of stop word to the whole word count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ratio of other word to the whole word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratioo = oscore/total #ratio of other word to the whole word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0221"
      ]
     },
     "execution_count": 680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(ratiop,4)  #rounded positive ratio to 4 decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0314"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(ration,4) #rounded negative ratio to 4 decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4241"
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(ratios,4) #rounded stopword ratio to 4 decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5224"
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(ratioo,4) #rounded other ratio to 4 decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "f3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "f4.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second word Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the tweet for NationalPetDay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf = open('NationalPetDay.txt','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet = nf.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample raw tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"RT @fusetv: .@ArianaGrande, @BritneySpears, @BTS_twt's V + 16 more celebs with their super cute pets \\xf0\\x9f\\x98\\x8d \\xe2\\x80\\x93 https://t.co/F4RQ0rxnIa #NationalP\\xe2\\x80\\xa6\\n\"b\"RT @firtsIove: happy #NationalPetDay to yoongi's puppy \\xe2\\x99\\xa1 https://t.co/3EPLVv7Rhs\\n\"b\"RT @fusetv: .@ArianaGrande, @BritneySpears, @BTS_twt's V + 16 more celebs with their super cute pets \\xf0\\x9f\\x98\\x8d \\xe2\\x80\\x93 https://t.co/F4RQ0rxnIa #NationalP\\xe2\\x80\\xa6\\n\"b'RT @icklenellierose: Happy #NationalPetDay https://t.co/1Pw5tnTB9O\\n'b\"RT @DeptofDefense: It\\xe2\\x80\\x99s #NationalPetDay \\xf0\\x9f\\x90\\xb6 and even though Chesty XV is just a puppy \\xf0\\x9f\\x90\\xbe, he's no pet because he is becoming a Marine, one com\\xe2\\x80\\xa6\\n\"b'someone is quite excited it\\xe2\\x80\\x99s #nationalpetday https://t.co/vClUTv3xC6\\n'b'RT @Jeep: Fluff riders. #NationalPetDay https://t.co/gsgnLv69Q0\\n'b\"RT @fusetv: .@ArianaGrande, @BritneySpears, @BTS_twt's V + 16 more celebs with their super cute pets \\xf0\\x9f\\x98\\x8d\n"
     ]
    }
   ],
   "source": [
    "print(pet[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 691,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pet)\n",
    "#to check the type "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of raw tweets for NationalPetDay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41546"
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning HTTP Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pet1 = re.sub(r\"http\\S+\", \"\", pet)    \n",
    "#Cleaning the http tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning embedded computer code with patter of \\xe2\\x80\\etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet2= re.sub(r'(\\\\x(.){2})', '',pet1) \n",
    "#Cleaning the embedded code by computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing the retweets and &amp, \\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\" @fusetv: .@ArianaGrande, @BritneySpears, @BTS_twt's V + 16 more celebs with their super cute pets    #NationalP\"b\" @firtsIove: happy #NationalPetDay to yoongi's puppy   @fusetv: .@ArianaGrande, @BritneySpears, @BTS_twt's V + 16 more celebs with their super cute pets    #NationalP\"b' @icklenellierose: Happy #NationalPetDay  @DeptofDefense: Its #NationalPetDay  and even though Chesty XV is just a puppy , he's no pet because he is becoming a Marine, one com\"b'someone is quite excited its #nationalpetday  @Jeep: Fluff riders. #NationalPetDay  @fusetv: .@ArianaGrande, @BritneySpears, @BTS_twt's V + 16 more celebs with their super cute pets    #NationalP\"b' @ChrisEvans: This is the moment we met. He was trying so hard to stay seated even though he desperately wanted to get out. I knew right'b\" @danicamckellar: It's #NationalPetDay! And the @americanhumane @herodogawards are the Oscars for dogs: Pick your favorite #HeroDogs for\"b\" @CMHSPets: Happy #NationalPetDay! We're so excited to annou\n"
     ]
    }
   ],
   "source": [
    "punc = ['RT','&amp','\\\\n']\n",
    "for j in punc:\n",
    "     if j in pet2:\n",
    "            pet2 = pet2.replace(j,'')\n",
    "#removing the Retweets and &amp tags\n",
    "\n",
    "print(pet2[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing all the punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "y = str.maketrans(\"\",\"\",string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet3 = pet2.translate(y)    \n",
    "#Result after cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing sample data after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b fusetv ArianaGrande BritneySpears BTStwts V  16 more celebs with their super cute pets    NationalPb firtsIove happy NationalPetDay to yoongis puppy   fusetv ArianaGrande BritneySpears BTStwts V  16 more celebs with their super cute pets    NationalPb icklenellierose Happy NationalPetDay  DeptofDefense Its NationalPetDay  and even though Chesty XV is just a puppy  hes no pet because he is becoming a Marine one combsomeone is quite excited its nationalpetday  Jeep Fluff riders NationalPetDay  fusetv ArianaGrande BritneySpears BTStwts V  16 more celebs with their super cute pets    NationalPb ChrisEvans This is the moment we met He was trying so hard to stay seated even though he desperately wanted to get out I knew rightb danicamckellar Its NationalPetDay And the americanhumane herodogawards are the Oscars for dogs Pick your favorite HeroDogs forb CMHSPets Happy NationalPetDay Were so excited to announce our Spring Fling Adoption Event happening this weekend April 1315 RedubHappy Nati\n"
     ]
    }
   ],
   "source": [
    "print(pet3[:1000]) \n",
    "#checking the cleaned data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of data after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26709"
      ]
     },
     "execution_count": 699,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pet3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pet3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To convert every character to lower case and then split it into list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "newpet = pet3.lower().split()\n",
    "#to convert every character to lower case and then split it into list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 702,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(newpet) #checking the type of new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b', 'fusetv', 'arianagrande', 'britneyspears', 'btstwts', 'v', '16', 'more', 'celebs', 'with', 'their', 'super', 'cute', 'pets', 'nationalpb', 'firtsiove', 'happy', 'nationalpetday', 'to', 'yoongis', 'puppy', 'fusetv', 'arianagrande', 'britneyspears', 'btstwts', 'v', '16', 'more', 'celebs', 'with', 'their', 'super', 'cute', 'pets', 'nationalpb', 'icklenellierose', 'happy', 'nationalpetday', 'deptofdefense', 'its', 'nationalpetday', 'and', 'even', 'though', 'chesty', 'xv', 'is', 'just', 'a', 'puppy', 'hes', 'no', 'pet', 'because', 'he', 'is', 'becoming', 'a', 'marine', 'one', 'combsomeone', 'is', 'quite', 'excited', 'its', 'nationalpetday', 'jeep', 'fluff', 'riders', 'nationalpetday', 'fusetv', 'arianagrande', 'britneyspears', 'btstwts', 'v', '16', 'more', 'celebs', 'with', 'their', 'super', 'cute', 'pets', 'nationalpb', 'chrisevans', 'this', 'is', 'the', 'moment', 'we', 'met', 'he', 'was', 'trying', 'so', 'hard', 'to', 'stay', 'seated', 'even']\n"
     ]
    }
   ],
   "source": [
    "print(newpet[:100]) #printing the sample of this list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of new list created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4320"
      ]
     },
     "execution_count": 704,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newpet) #length of new after list creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Positive words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf2 = open('positive.txt','r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To read positive word list, change every character to lower case and split it into list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwt = nf2.read().lower().split()\n",
    "#to read positive word list, change every character to lower case and split it into list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 707,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pwt) \n",
    "#type of pw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of positive words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2006"
      ]
     },
     "execution_count": 708,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pwt)\n",
    "#number of positive words in list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample of positive words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a+', 'abound', 'abounds', 'abundance', 'abundant', 'accessable', 'accessible', 'acclaim', 'acclaimed', 'acclamation', 'accolade', 'accolades', 'accommodative', 'accomodative', 'accomplish', 'accomplished', 'accomplishment', 'accomplishments', 'accurate', 'accurately', 'achievable', 'achievement', 'achievements', 'achievible', 'acumen', 'adaptable', 'adaptive', 'adequate', 'adjustable', 'admirable', 'admirably', 'admiration', 'admire', 'admirer', 'admiring', 'admiringly', 'adorable', 'adore', 'adored', 'adorer', 'adoring', 'adoringly', 'adroit', 'adroitly', 'adulate', 'adulation', 'adulatory', 'advanced', 'advantage', 'advantageous', 'advantageously', 'advantages', 'adventuresome', 'adventurous', 'advocate', 'advocated', 'advocates', 'affability', 'affable', 'affably', 'affectation', 'affection', 'affectionate', 'affinity', 'affirm', 'affirmation', 'affirmative', 'affluence', 'affluent', 'afford', 'affordable', 'affordably', 'afordable', 'agile', 'agilely', 'agility', 'agreeable', 'agreeableness', 'agreeably', 'all-around', 'alluring', 'alluringly', 'altruistic', 'altruistically', 'amaze', 'amazed', 'amazement', 'amazes', 'amazing', 'amazingly', 'ambitious', 'ambitiously', 'ameliorate', 'amenable', 'amenity', 'amiability', 'amiabily', 'amiable', 'amicability', 'amicable']\n"
     ]
    }
   ],
   "source": [
    "print(pwt[:100])\n",
    "#printing the sampled list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf3 = open('neg.txt','r',encoding = \"ISO-8859-1\")\n",
    "#opening the file with negative word, since was in another format so converted to ISO format for compatibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the negative word list, changed it to lower case and then split them to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwt = nf3.read().lower().split()\n",
    "#read the negative word list, changed it to lower case and then split them to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 712,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nwt) \n",
    "#to check the type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4783"
      ]
     },
     "execution_count": 713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nwt)\n",
    "#to check the length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample of negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2-faced', '2-faces', 'abnormal', 'abolish', 'abominable', 'abominably', 'abominate', 'abomination', 'abort', 'aborted', 'aborts', 'abrade', 'abrasive', 'abrupt', 'abruptly', 'abscond', 'absence', 'absent-minded', 'absentee', 'absurd', 'absurdity', 'absurdly', 'absurdness', 'abuse', 'abused', 'abuses', 'abusive', 'abysmal', 'abysmally', 'abyss', 'accidental', 'accost', 'accursed', 'accusation', 'accusations', 'accuse', 'accuses', 'accusing', 'accusingly', 'acerbate', 'acerbic', 'acerbically', 'ache', 'ached', 'aches', 'achey', 'aching', 'acrid', 'acridly', 'acridness', 'acrimonious', 'acrimoniously', 'acrimony', 'adamant', 'adamantly', 'addict', 'addicted', 'addicting', 'addicts', 'admonish', 'admonisher', 'admonishingly', 'admonishment', 'admonition', 'adulterate', 'adulterated', 'adulteration', 'adulterier', 'adversarial', 'adversary', 'adverse', 'adversity', 'afflict', 'affliction', 'afflictive', 'affront', 'afraid', 'aggravate', 'aggravating', 'aggravation', 'aggression', 'aggressive', 'aggressiveness', 'aggressor', 'aggrieve', 'aggrieved', 'aggrivation', 'aghast', 'agonies', 'agonize', 'agonizing', 'agonizingly', 'agony', 'aground', 'ail', 'ailing', 'ailment', 'aimless', 'alarm', 'alarmed']\n"
     ]
    }
   ],
   "source": [
    "print(nwt[:100])\n",
    "#to print the sample of negative words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import stop words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf4 = open('stopwords.txt','r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the stop word list, changed it to lower case and then split them to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "swt = nf4.read().lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "423"
      ]
     },
     "execution_count": 717,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(swt)\n",
    "#length of stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample of Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'across', 'after', 'again', 'against', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'among', 'an', 'and', 'another', 'any', 'anybody', 'anyone', 'anything', 'anywhere', 'are', 'area', 'areas', 'around', 'as', 'ask', 'asked', 'asking', 'asks', 'at', 'away', 'b', 'back', 'backed', 'backing', 'backs', 'be', 'became', 'because', 'become', 'becomes', 'been', 'before', 'began', 'behind', 'being', 'beings', 'best', 'better', 'between', 'big', 'both', 'but', 'by', 'c', 'came', 'can', 'cannot', 'case', 'cases', 'certain', 'certainly', 'clear', 'clearly', 'come', 'could', 'd', 'did', 'differ', 'different', 'differently', 'do', 'does', 'done', 'down', 'downed', 'downing', 'downs', 'during', 'e', 'each', 'early', 'either', 'end', 'ended', 'ending', 'ends', 'enough', 'even', 'evenly', 'ever', 'every', 'everybody', 'everyone', 'everything', 'everywhere']\n"
     ]
    }
   ],
   "source": [
    "print(swt[:100])\n",
    "#printing the stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the positive, negative, stop and other words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "petpscore = 0 #to initialize the positive score variable\n",
    "pp1 = []    #to create a list\n",
    "petnscore = 0\n",
    "np1 = []\n",
    "petsscore = 0\n",
    "sp1 = []\n",
    "petoscore = 0\n",
    "op1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in newpet: \n",
    "    if i in pwt: \n",
    "        petpscore += 1\n",
    "        pp1.append(i)\n",
    "    elif i in nwt:\n",
    "        petnscore -=1\n",
    "        np1.append(i)\n",
    "    elif i in swt:\n",
    "        petsscore +=1\n",
    "        sp1.append(i)\n",
    "    else:\n",
    "        petoscore +=1\n",
    "        op1.append(i)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total positive word count in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231\n"
     ]
    }
   ],
   "source": [
    "print(petpscore) #total positive score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Negative word count in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-126\n"
     ]
    }
   ],
   "source": [
    "print(petnscore)#total negative score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Stop word count in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2112\n"
     ]
    }
   ],
   "source": [
    "print(petsscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total other word count in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1851\n"
     ]
    }
   ],
   "source": [
    "print(petoscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:  From the above code, out of total 4320 words, 231 are positive and 126 are negative, 2112 are stop words. The general sentiment of people for National Pet Day is positive. Now, to determine weakly or strongly, lets calculate ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8333333333333333"
      ]
     },
     "execution_count": 725,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testratio= abs(petpscore/petnscore)\n",
    "testratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> I have defined the ratio here as: \n",
    "    <li> I defined:</li>\n",
    "    <li>if abs(ratio)  >=0 and < 0.5 -> strongly negative </li>\n",
    "    <li>abs(ratio) >= 0.5 and < 1 -> weakly negative</li>\n",
    "    <li>abs(ratio) >=1 and < 1.5 -> weakly positive</li>\n",
    "    <li>abs(ratio) >=1.5  -> strongly positive</li></b>\n",
    "    \n",
    "###  Since ratio is 1.83 Based on the analysis here I think that the sentiment is strongly positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4320"
      ]
     },
     "execution_count": 726,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumpet = petpscore + abs(petnscore) + petsscore + petoscore\n",
    "sumpet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05347222222222222"
      ]
     },
     "execution_count": 727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pratio = petpscore/sumpet\n",
    "pratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029166666666666667"
      ]
     },
     "execution_count": 728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nratio = abs(petnscore)/sumpet\n",
    "nratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4888888888888889"
      ]
     },
     "execution_count": 729,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sratio = petsscore/sumpet\n",
    "sratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4284722222222222"
      ]
     },
     "execution_count": 730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oratio = petoscore/sumpet\n",
    "oratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf4.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
